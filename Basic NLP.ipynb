{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./.venv/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"Generative artificial intelligence (generative AI, GenAI,[1] or GAI) is a subset of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data.[2][3][4] These models learn the underlying patterns and structures of their training data and use them to produce new data[5][6] based on the input, which often comes in the form of natural language prompts.[7][8]. Improvements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the 2020s. These include chatbots such as ChatGPT, Copilot, Gemini, and LLaMA; text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video AI generators such as Sora.[9][10][11][12] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.[7][13][14]. Generative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service,[15] sales and marketing,[16] art, writing,[17] fashion,[18] and product design.[19] However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.[20][21] Intellectual property law concerns also exist around generative models that are trained on and emulate copyrighted works of art.[22]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generative artificial intelligence (generative AI, GenAI,[1] or GAI) is a subset of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data.[2][3][4] These models learn the underlying patterns and structures of their training data and use them to produce new data[5][6] based on the input, which often comes in the form of natural language prompts.[7][8]. Improvements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the 2020s. These include chatbots such as ChatGPT, Copilot, Gemini, and LLaMA; text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video AI generators such as Sora.[9][10][11][12] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.[7][13][14]. Generative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service,[15] sales and marketing,[16] art, writing,[17] fashion,[18] and product design.[19] However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.[20][21] Intellectual property law concerns also exist around generative models that are trained on and emulate copyrighted works of art.[22]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rishikeshkakde/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Tokenization -> paragraphs into sentences into words\n",
    "nltk.download('punkt')\n",
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Generative artificial intelligence (generative AI, GenAI,[1] or GAI) is a subset of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data.',\n",
       " '[2][3][4] These models learn the underlying patterns and structures of their training data and use them to produce new data[5][6] based on the input, which often comes in the form of natural language prompts.[7][8].',\n",
       " 'Improvements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the 2020s.',\n",
       " 'These include chatbots such as ChatGPT, Copilot, Gemini, and LLaMA; text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video AI generators such as Sora.',\n",
       " '[9][10][11][12] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.[7][13][14].',\n",
       " 'Generative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service,[15] sales and marketing,[16] art, writing,[17] fashion,[18] and product design.',\n",
       " '[19] However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.',\n",
       " '[20][21] Intellectual property law concerns also exist around generative models that are trained on and emulate copyrighted works of art.',\n",
       " '[22]']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('Having')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'History'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('History')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that lemmatizer gives the proper meaningful reduction of the word 'History'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, remove the special characters in the tetx with Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
    "    review = review.lower()\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['generative artificial intelligence  generative ai  genai     or gai  is a subset of artificial intelligence that uses generative models to produce text  images  videos  or other forms of data ',\n",
       " '          these models learn the underlying patterns and structures of their training data and use them to produce new data       based on the input  which often comes in the form of natural language prompts        ',\n",
       " 'improvements in transformer based deep neural networks  particularly large language models  llms   enabled an ai boom of generative ai systems in the     s ',\n",
       " 'these include chatbots such as chatgpt  copilot  gemini  and llama  text to image artificial intelligence image generation systems such as stable diffusion  midjourney  and dall e  and text to video ai generators such as sora ',\n",
       " '                companies such as openai  anthropic  microsoft  google  and baidu as well as numerous smaller firms have developed generative ai models             ',\n",
       " 'generative ai has uses across a wide range of industries  including software development  healthcare  finance  entertainment  customer service      sales and marketing      art  writing      fashion      and product design ',\n",
       " '     however  concerns have been raised about the potential misuse of generative ai such as cybercrime  the use of fake news or deepfakes to deceive or manipulate people  and the mass replacement of human jobs ',\n",
       " '         intellectual property law concerns also exist around generative models that are trained on and emulate copyrighted works of art ',\n",
       " '    ']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gener\n",
      "artifici\n",
      "intellig\n",
      "gener\n",
      "ai\n",
      "genai\n",
      "gai\n",
      "subset\n",
      "artifici\n",
      "intellig\n",
      "use\n",
      "gener\n",
      "model\n",
      "produc\n",
      "text\n",
      "imag\n",
      "video\n",
      "form\n",
      "data\n",
      "model\n",
      "learn\n",
      "underli\n",
      "pattern\n",
      "structur\n",
      "train\n",
      "data\n",
      "use\n",
      "produc\n",
      "new\n",
      "data\n",
      "base\n",
      "input\n",
      "often\n",
      "come\n",
      "form\n",
      "natur\n",
      "languag\n",
      "prompt\n",
      "improv\n",
      "transform\n",
      "base\n",
      "deep\n",
      "neural\n",
      "network\n",
      "particularli\n",
      "larg\n",
      "languag\n",
      "model\n",
      "llm\n",
      "enabl\n",
      "ai\n",
      "boom\n",
      "gener\n",
      "ai\n",
      "system\n",
      "includ\n",
      "chatbot\n",
      "chatgpt\n",
      "copilot\n",
      "gemini\n",
      "llama\n",
      "text\n",
      "imag\n",
      "artifici\n",
      "intellig\n",
      "imag\n",
      "gener\n",
      "system\n",
      "stabl\n",
      "diffus\n",
      "midjourney\n",
      "dall\n",
      "e\n",
      "text\n",
      "video\n",
      "ai\n",
      "gener\n",
      "sora\n",
      "compani\n",
      "openai\n",
      "anthrop\n",
      "microsoft\n",
      "googl\n",
      "baidu\n",
      "well\n",
      "numer\n",
      "smaller\n",
      "firm\n",
      "develop\n",
      "gener\n",
      "ai\n",
      "model\n",
      "gener\n",
      "ai\n",
      "use\n",
      "across\n",
      "wide\n",
      "rang\n",
      "industri\n",
      "includ\n",
      "softwar\n",
      "develop\n",
      "healthcar\n",
      "financ\n",
      "entertain\n",
      "custom\n",
      "servic\n",
      "sale\n",
      "market\n",
      "art\n",
      "write\n",
      "fashion\n",
      "product\n",
      "design\n",
      "howev\n",
      "concern\n",
      "rais\n",
      "potenti\n",
      "misus\n",
      "gener\n",
      "ai\n",
      "cybercrim\n",
      "use\n",
      "fake\n",
      "news\n",
      "deepfak\n",
      "deceiv\n",
      "manipul\n",
      "peopl\n",
      "mass\n",
      "replac\n",
      "human\n",
      "job\n",
      "intellectu\n",
      "properti\n",
      "law\n",
      "concern\n",
      "also\n",
      "exist\n",
      "around\n",
      "gener\n",
      "model\n",
      "train\n",
      "emul\n",
      "copyright\n",
      "work\n",
      "art\n"
     ]
    }
   ],
   "source": [
    "for i in corpus:\n",
    "    words = nltk.word_tokenize(i)\n",
    "    for word in words:\n",
    "        if word not in set(stopwords.words('english')):\n",
    "            print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generative\n",
      "artificial\n",
      "intelligence\n",
      "generative\n",
      "ai\n",
      "genai\n",
      "gai\n",
      "subset\n",
      "artificial\n",
      "intelligence\n",
      "us\n",
      "generative\n",
      "model\n",
      "produce\n",
      "text\n",
      "image\n",
      "video\n",
      "form\n",
      "data\n",
      "model\n",
      "learn\n",
      "underlying\n",
      "pattern\n",
      "structure\n",
      "training\n",
      "data\n",
      "use\n",
      "produce\n",
      "new\n",
      "data\n",
      "based\n",
      "input\n",
      "often\n",
      "come\n",
      "form\n",
      "natural\n",
      "language\n",
      "prompt\n",
      "improvement\n",
      "transformer\n",
      "based\n",
      "deep\n",
      "neural\n",
      "network\n",
      "particularly\n",
      "large\n",
      "language\n",
      "model\n",
      "llm\n",
      "enabled\n",
      "ai\n",
      "boom\n",
      "generative\n",
      "ai\n",
      "system\n",
      "include\n",
      "chatbots\n",
      "chatgpt\n",
      "copilot\n",
      "gemini\n",
      "llama\n",
      "text\n",
      "image\n",
      "artificial\n",
      "intelligence\n",
      "image\n",
      "generation\n",
      "system\n",
      "stable\n",
      "diffusion\n",
      "midjourney\n",
      "dall\n",
      "e\n",
      "text\n",
      "video\n",
      "ai\n",
      "generator\n",
      "sora\n",
      "company\n",
      "openai\n",
      "anthropic\n",
      "microsoft\n",
      "google\n",
      "baidu\n",
      "well\n",
      "numerous\n",
      "smaller\n",
      "firm\n",
      "developed\n",
      "generative\n",
      "ai\n",
      "model\n",
      "generative\n",
      "ai\n",
      "us\n",
      "across\n",
      "wide\n",
      "range\n",
      "industry\n",
      "including\n",
      "software\n",
      "development\n",
      "healthcare\n",
      "finance\n",
      "entertainment\n",
      "customer\n",
      "service\n",
      "sale\n",
      "marketing\n",
      "art\n",
      "writing\n",
      "fashion\n",
      "product\n",
      "design\n",
      "however\n",
      "concern\n",
      "raised\n",
      "potential\n",
      "misuse\n",
      "generative\n",
      "ai\n",
      "cybercrime\n",
      "use\n",
      "fake\n",
      "news\n",
      "deepfakes\n",
      "deceive\n",
      "manipulate\n",
      "people\n",
      "mass\n",
      "replacement\n",
      "human\n",
      "job\n",
      "intellectual\n",
      "property\n",
      "law\n",
      "concern\n",
      "also\n",
      "exist\n",
      "around\n",
      "generative\n",
      "model\n",
      "trained\n",
      "emulate\n",
      "copyrighted\n",
      "work\n",
      "art\n"
     ]
    }
   ],
   "source": [
    "for i in corpus:\n",
    "    words = nltk.word_tokenize(i)\n",
    "    for word in words:\n",
    "        if word not in set(stopwords.words('english')):\n",
    "            print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply stopwords. Lemmatize\n",
    "import re\n",
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generative': 41,\n",
       " 'artificial': 6,\n",
       " 'intelligence': 54,\n",
       " 'ai': 1,\n",
       " 'genai': 39,\n",
       " 'gai': 37,\n",
       " 'subset': 95,\n",
       " 'us': 102,\n",
       " 'model': 68,\n",
       " 'produce': 81,\n",
       " 'text': 97,\n",
       " 'image': 47,\n",
       " 'video': 104,\n",
       " 'form': 36,\n",
       " 'data': 20,\n",
       " 'learn': 59,\n",
       " 'underlying': 101,\n",
       " 'pattern': 78,\n",
       " 'structure': 94,\n",
       " 'training': 99,\n",
       " 'use': 103,\n",
       " 'new': 72,\n",
       " 'based': 8,\n",
       " 'input': 52,\n",
       " 'often': 75,\n",
       " 'come': 12,\n",
       " 'natural': 69,\n",
       " 'language': 56,\n",
       " 'prompt': 83,\n",
       " 'improvement': 48,\n",
       " 'transformer': 100,\n",
       " 'deep': 22,\n",
       " 'neural': 71,\n",
       " 'network': 70,\n",
       " 'particularly': 77,\n",
       " 'large': 57,\n",
       " 'llm': 61,\n",
       " 'enabled': 29,\n",
       " 'boom': 9,\n",
       " 'system': 96,\n",
       " 'include': 49,\n",
       " 'chatbots': 10,\n",
       " 'chatgpt': 11,\n",
       " 'copilot': 15,\n",
       " 'gemini': 38,\n",
       " 'llama': 60,\n",
       " 'generation': 40,\n",
       " 'stable': 93,\n",
       " 'diffusion': 27,\n",
       " 'midjourney': 66,\n",
       " 'dall': 19,\n",
       " 'generator': 42,\n",
       " 'sora': 92,\n",
       " 'company': 13,\n",
       " 'openai': 76,\n",
       " 'anthropic': 3,\n",
       " 'microsoft': 65,\n",
       " 'google': 43,\n",
       " 'baidu': 7,\n",
       " 'well': 105,\n",
       " 'numerous': 74,\n",
       " 'smaller': 90,\n",
       " 'firm': 35,\n",
       " 'developed': 25,\n",
       " 'across': 0,\n",
       " 'wide': 106,\n",
       " 'range': 86,\n",
       " 'industry': 51,\n",
       " 'including': 50,\n",
       " 'software': 91,\n",
       " 'development': 26,\n",
       " 'healthcare': 44,\n",
       " 'finance': 34,\n",
       " 'entertainment': 30,\n",
       " 'customer': 17,\n",
       " 'service': 89,\n",
       " 'sale': 88,\n",
       " 'marketing': 63,\n",
       " 'art': 5,\n",
       " 'writing': 108,\n",
       " 'fashion': 33,\n",
       " 'product': 82,\n",
       " 'design': 24,\n",
       " 'however': 45,\n",
       " 'concern': 14,\n",
       " 'raised': 85,\n",
       " 'potential': 80,\n",
       " 'misuse': 67,\n",
       " 'cybercrime': 18,\n",
       " 'fake': 32,\n",
       " 'news': 73,\n",
       " 'deepfakes': 23,\n",
       " 'deceive': 21,\n",
       " 'manipulate': 62,\n",
       " 'people': 79,\n",
       " 'mass': 64,\n",
       " 'replacement': 87,\n",
       " 'human': 46,\n",
       " 'job': 55,\n",
       " 'intellectual': 53,\n",
       " 'property': 84,\n",
       " 'law': 58,\n",
       " 'also': 2,\n",
       " 'exist': 31,\n",
       " 'around': 4,\n",
       " 'trained': 98,\n",
       " 'emulate': 28,\n",
       " 'copyrighted': 16,\n",
       " 'work': 107}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 3, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'generative artificial intelligence generative ai genai gai subset artificial intelligence us generative model produce text image video form data'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.1270764 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4128814 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2064407 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.2064407 , 0.24441962, 0.        , 0.24441962,\n",
       "        0.        , 0.3812292 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2064407 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.4128814 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.14151531, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.2064407 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.24441962, 0.        , 0.2064407 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2064407 , 0.        , 0.2064407 ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
